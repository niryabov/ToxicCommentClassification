text_column: comment_text

clean:
  lowercase: true
  remove_punctuation: true
  collapse_whitespace: true
  strip: true

split:
  # Match the reference Keras snippet: train_size=0.95, random_state=233
  train_size: 0.95
  val_size: null
  random_state: 233

vocab:
  # Match Keras Tokenizer(num_words=max_features)
  max_size: 30000
  min_freq: 1
  unk_token: "[UNK]"
  pad_token: "[PAD]"
  # Match Keras tokenizer fit_on_texts(list(X_train)+list(X_test))
  fit_on_test: true
  # Match Keras: OOV tokens are effectively dropped (no oov_token used)
  drop_oov: true

tokenize:
  # Match Keras pad_sequences(..., maxlen=100) with default padding='pre', truncating='pre'
  max_length: 100

synthetic:
  n_train: 256
  n_val: 64
  n_test: 64
